{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d068de4d-3faa-4742-837a-501771729f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2-binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\NP.MOHSENPAK\\\\anaconda3\\\\Lib\\\\site-packages\\\\psycopg2\\\\_psycopg.cp312-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install psycopg2-binary  #to verify that your AWS RDS PostgreSQL connection is working correctly, you can use a Python script with the psycopg2 library to test the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd59550-73a6-4511-962b-f2cc88ab0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "rds_host = os.getenv(\"RDS_HOST\")\n",
    "rds_user = os.getenv(\"RDS_USER\")\n",
    "rds_password = os.getenv(\"RDS_PASSWORD\")\n",
    "rds_db = os.getenv(\"RDS_DB\")\n",
    "rds_port = os.getenv(\"RDS_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37acb7d2-2188-4450-b38e-0174afd32c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDS Host: database-1.c2b8mmg2krpj.us-east-1.rds.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "print(f\"RDS Host: {rds_host}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8423a104-d811-4580-b071-8828604a4eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully saved to AWS RDS PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text  # <-- Added text\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Step 1: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "\n",
    "# Step 2: Download Apple stock data\n",
    "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2024-04-01\")\n",
    "\n",
    "# Step 3: Flatten MultiIndex columns if necessary\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = [f'{col[0]}_{col[1]}' for col in data.columns]\n",
    "\n",
    "# Reset the index to make 'Date' a regular column\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Convert 'Date' column to string format\n",
    "data['Date'] = data['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Step 4: Connect to AWS RDS PostgreSQL\n",
    "engine = create_engine(f'postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}')\n",
    "\n",
    "# Step 5: Create table if not exists\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS apple_stock (\n",
    "    Date TEXT PRIMARY KEY,\n",
    "    Open_AAPL REAL,\n",
    "    High_AAPL REAL,\n",
    "    Low_AAPL REAL,\n",
    "    Close_AAPL REAL,\n",
    "    \"Adj Close_AAPL\" REAL,\n",
    "    Volume_AAPL BIGINT\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the table creation query\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table_query))\n",
    "\n",
    "# Step 6: Insert data into PostgreSQL\n",
    "data.to_sql('apple_stock', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"✅ Data successfully saved to AWS RDS PostgreSQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf074e4-6f5f-48f0-8df1-bbb7ae9a20ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close_AAPL</th>\n",
       "      <th>Close_AAPL</th>\n",
       "      <th>High_AAPL</th>\n",
       "      <th>Low_AAPL</th>\n",
       "      <th>Open_AAPL</th>\n",
       "      <th>Volume_AAPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Adj Close_AAPL, Close_AAPL, High_AAPL, Low_AAPL, Open_AAPL, Volume_AAPL]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85ee713-dfd1-4539-b862-ac792dddf21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NP.MOHSENPAK\\AppData\\Local\\Temp\\ipykernel_33640\\1872282955.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_aapl.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL stock data cleaned and saved to PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 3: AWS RDS PostgreSQL Connection Details\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Step 1: Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "\n",
    "# Create PostgreSQL connection using SQLAlchemy\n",
    "engine = create_engine(f'postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}')\n",
    "\n",
    "# Load AAPL stock data\n",
    "df_aapl = pd.read_sql(\"SELECT * FROM apple_stock\", engine)\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "df_aapl['Date'] = pd.to_datetime(df_aapl['Date'])\n",
    "\n",
    "# Handle missing values (forward fill for stock prices)\n",
    "df_aapl.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df_aapl.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned AAPL data back to PostgreSQL\n",
    "df_aapl.to_sql(\"apple_stock\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"AAPL stock data cleaned and saved to PostgreSQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b43655-32e8-4733-a787-eb0cb84b5550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Close_AAPL', 'High_AAPL', 'Low_AAPL', 'Open_AAPL',\n",
      "       'Volume_AAPL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_aapl.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949b6fb7-e3a6-4734-bd4c-5ceeeee29ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ News sentiment data successfully saved to AWS RDS PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "#sentiment Analysis\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Initialize Sentiment Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Step 1: Fetch news data from NewsAPI\n",
    "API_KEY = os.getenv(\"NEWS_API_KEY\")  # Ensure API key is set\n",
    "\n",
    "url = f\"https://newsapi.org/v2/everything?q=stock&apiKey={API_KEY}\"\n",
    "response = requests.get(url).json()\n",
    "\n",
    "# Step 2: Extract relevant fields and convert to DataFrame\n",
    "articles = response.get(\"articles\", [])\n",
    "\n",
    "# Check if data is available\n",
    "if not articles:\n",
    "    raise ValueError(\"❌ No articles found in API response. Check your API key and query.\")\n",
    "\n",
    "df_news = pd.DataFrame(articles)\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = [\"publishedAt\", \"title\", \"description\", \"url\"]\n",
    "df_news = df_news[[col for col in required_columns if col in df_news.columns]]\n",
    "\n",
    "# Convert 'publishedAt' to datetime format if it exists\n",
    "if \"publishedAt\" in df_news.columns:\n",
    "    df_news[\"publishedAt\"] = pd.to_datetime(df_news[\"publishedAt\"])\n",
    "\n",
    "# Perform Sentiment Analysis on each news title\n",
    "df_news[\"sentiment_score\"] = df_news[\"title\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"] if isinstance(x, str) else 0)\n",
    "df_news[\"sentiment_label\"] = df_news[\"sentiment_score\"].apply(lambda x: \"positive\" if x > 0 else (\"negative\" if x < 0 else \"neutral\"))\n",
    "\n",
    "# AWS RDS PostgreSQL connection details\n",
    "\n",
    "\n",
    "# Step 1: Load environment variables\n",
    "\n",
    "\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "\n",
    "# Step 4: Create PostgreSQL connection using SQLAlchemy\n",
    "engine = create_engine(f'postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}')\n",
    "\n",
    "# Step 5: Create table in PostgreSQL if it doesn’t exist\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS financial_news_sentiment (\n",
    "    publishedAt TIMESTAMP,\n",
    "    title TEXT,\n",
    "    description TEXT,\n",
    "    url TEXT PRIMARY KEY,\n",
    "    sentiment_score REAL,\n",
    "    sentiment_label TEXT\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute table creation\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table_query))\n",
    "\n",
    "# Step 6: Insert data into AWS RDS PostgreSQL\n",
    "df_news.to_sql('financial_news_sentiment', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"✅ News sentiment data successfully saved to AWS RDS PostgreSQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a2258-60e3-4eb5-ad68-7e51502c50c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce535c6-0a39-4d9d-92ab-3cfabf115d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial news sentiment data cleaned and saved to PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# AWS RDS PostgreSQL connection details\n",
    "# Step 1: Load environment variables\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "# Step 4: Create PostgreSQL connection using SQLAlchemy\n",
    "engine = create_engine(f'postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}')\n",
    "\n",
    "\n",
    "\n",
    "# Load financial news sentiment data\n",
    "df_news = pd.read_sql(\"SELECT * FROM financial_news_sentiment\", engine)\n",
    "\n",
    "# Convert 'publishedAt' to datetime\n",
    "df_news['publishedAt'] = pd.to_datetime(df_news['publishedAt'])\n",
    "\n",
    "# Handle missing values\n",
    "df_news.fillna({\"sentiment_score\": 0, \"sentiment_label\": \"neutral\"}, inplace=True)  # Default sentiment for missing values\n",
    "\n",
    "# Remove duplicates\n",
    "df_news.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned news sentiment data back to PostgreSQL\n",
    "df_news.to_sql(\"financial_news_sentiment\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"Financial news sentiment data cleaned and saved to PostgreSQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa145a2-b774-407c-8ec8-eca81237df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2-binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\NP.MOHSENPAK\\\\anaconda3\\\\Lib\\\\site-packages\\\\psycopg2\\\\_psycopg.cp312-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d451d9-9f8d-4c6d-b7f0-1da83b68679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "\n",
    "API_KEY = os.getenv(\"NEWS_API_KEY\")  # Fetch from environment variable\n",
    "url = f\"https://newsapi.org/v2/everything?q=stock&apiKey={API_KEY}\"\n",
    "\n",
    "response = requests.get(url).json()\n",
    "#print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e088f448-ab90-4c92-b030-32d4a47cc869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NP.MOHSENPAK\\AppData\\Local\\Temp\\ipykernel_28276\\622479028.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_news[\"title\"].fillna(\"No title\", inplace=True)\n",
      "C:\\Users\\NP.MOHSENPAK\\AppData\\Local\\Temp\\ipykernel_28276\\622479028.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_news[\"description\"].fillna(\"No description\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                publishedAt  \\\n",
      "0 2025-04-22 11:09:00+00:00   \n",
      "1 2025-04-03 14:38:12+00:00   \n",
      "2 2025-04-03 14:13:00+00:00   \n",
      "3 2025-04-07 17:32:00+00:00   \n",
      "4 2025-04-01 14:10:07+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0          7 best ecofriendly cleaning products 2025   \n",
      "1  apple has its biggest stock drop in five years...   \n",
      "2  apple has its biggest stock drop in five years...   \n",
      "3  stocks plunge after trump declares web rumor o...   \n",
      "4  star wars harry potter amazon clears stock of ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  next time you stock up on supplies consider th...   \n",
      "1  shares of apple amazon and other tech stocks a...   \n",
      "2  shares of apple amazon and other tech stocks a...   \n",
      "3  the stock market had a brief moment of hope on...   \n",
      "4                            first come first served   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.wired.com/gallery/best-eco-friendl...  \n",
      "1  https://www.theverge.com/news/642598/apple-sto...  \n",
      "2  https://www.theverge.com/news/642598/apple-ama...  \n",
      "3  https://gizmodo.com/stocks-plunge-after-trump-...  \n",
      "4  https://gizmodo.com/star-wars-harry-potter-ama...  \n",
      "Financial news cleaned and saved to AWS RDS PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API Key from environment variables\n",
    "API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "# Fetch financial news from NewsAPI\n",
    "url = f\"https://newsapi.org/v2/everything?q=stock&apiKey={API_KEY}\"\n",
    "response = requests.get(url).json()\n",
    "\n",
    "# Extract relevant fields from the response\n",
    "articles = response.get(\"articles\", [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_news = pd.DataFrame(articles)[[\"publishedAt\", \"title\", \"description\", \"url\"]]\n",
    "\n",
    "# 1️⃣ Convert `publishedAt` to datetime format\n",
    "df_news[\"publishedAt\"] = pd.to_datetime(df_news[\"publishedAt\"], errors='coerce')\n",
    "\n",
    "# 2️⃣ Handle missing values\n",
    "df_news[\"title\"].fillna(\"No title\", inplace=True)\n",
    "df_news[\"description\"].fillna(\"No description\", inplace=True)\n",
    "\n",
    "# 3️⃣ Remove duplicate articles (based on title & description)\n",
    "df_news.drop_duplicates(subset=[\"title\", \"description\"], inplace=True)\n",
    "\n",
    "# 4️⃣ Perform text cleaning (optional)\n",
    "df_news[\"title\"] = df_news[\"title\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True).str.lower()\n",
    "df_news[\"description\"] = df_news[\"description\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True).str.lower()\n",
    "\n",
    "# ✅ Print cleaned data preview\n",
    "print(df_news.head())\n",
    "\n",
    "# 5️⃣ Save cleaned data to AWS RDS PostgreSQL\n",
    "# Step 4: AWS RDS PostgreSQL Connection Details\n",
    "# AWS RDS PostgreSQL connection details\n",
    "# Step 1: Load environment variables\n",
    "\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "\n",
    "# Create PostgreSQL connection using SQLAlchemy\n",
    "engine = create_engine(f'postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}')\n",
    "\n",
    "\n",
    "# Save to PostgreSQL\n",
    "df_news.to_sql(\"financial_news\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"Financial news cleaned and saved to AWS RDS PostgreSQL successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88154a65-8b45-487c-8868-1f08e857a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fredapi\n",
      "  Downloading fredapi-0.5.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from fredapi) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from pandas->fredapi) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from pandas->fredapi) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from pandas->fredapi) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from pandas->fredapi) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\np.mohsenpak\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.16.0)\n",
      "Downloading fredapi-0.5.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: fredapi\n",
      "Successfully installed fredapi-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fredapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "220ec351-dc45-491b-acc2-06b7236edf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic indicators (2023–2025) cleaned and saved to AWS RDS PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "#2023 t0 2025  data\n",
    "\n",
    "from fredapi import Fred\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get FRED API Key from environment variable\n",
    "API_KEY = os.getenv(\"FRED_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"FRED_API_KEY not found in environment variables\")\n",
    "\n",
    "# Initialize FRED client\n",
    "fred = Fred(api_key=API_KEY)\n",
    "\n",
    "# Define date range: 2023 to 2025\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2025, 12, 31)\n",
    "\n",
    "# Fetch economic indicators within the date range\n",
    "gdp = fred.get_series(\"GDP\", observation_start=start_date, observation_end=end_date)\n",
    "unemployment = fred.get_series(\"UNRATE\", observation_start=start_date, observation_end=end_date)\n",
    "\n",
    "# Combine into DataFrame\n",
    "df_economic = pd.DataFrame({\n",
    "    \"GDP\": gdp,\n",
    "    \"Unemployment_Rate\": unemployment\n",
    "})\n",
    "\n",
    "# Clean Data\n",
    "df_economic.dropna(inplace=True)\n",
    "df_economic.drop_duplicates(inplace=True)\n",
    "df_economic.reset_index(inplace=True)\n",
    "df_economic.rename(columns={'index': 'Date'}, inplace=True)\n",
    "df_economic['Date'] = pd.to_datetime(df_economic['Date'])\n",
    "\n",
    "# AWS RDS PostgreSQL connection details\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "rds_db = os.getenv('RDS_DB')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "\n",
    "# Create PostgreSQL connection string\n",
    "conn_str = f\"postgresql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}\"\n",
    "\n",
    "# Upload DataFrame to AWS PostgreSQL\n",
    "engine = create_engine(conn_str)\n",
    "df_economic.to_sql(\"economic_indicators\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"Economic indicators (2023–2025) cleaned and saved to AWS RDS PostgreSQL successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df2ff5aa-b5d1-4f7f-8915-f1aba0087b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Unemployment_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>27164.359</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>27453.815</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>27967.697</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>28296.967</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>28624.069</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>29016.714</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>29374.914</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>29723.864</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        GDP  Unemployment_Rate\n",
       "0 2023-01-01  27164.359                3.5\n",
       "1 2023-04-01  27453.815                3.4\n",
       "2 2023-07-01  27967.697                3.5\n",
       "3 2023-10-01  28296.967                3.9\n",
       "4 2024-01-01  28624.069                3.7\n",
       "5 2024-04-01  29016.714                3.9\n",
       "6 2024-07-01  29374.914                4.2\n",
       "7 2024-10-01  29723.864                4.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56168218-4db1-40a9-b750-e040bd83d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date        GDP  Unemployment_Rate\n",
      "0   1948-01-01    265.742                3.4\n",
      "1   1948-04-01    272.567                3.9\n",
      "2   1948-07-01    279.196                3.6\n",
      "3   1948-10-01    280.366                3.7\n",
      "4   1949-01-01    275.034                4.3\n",
      "..         ...        ...                ...\n",
      "303 2023-10-01  28296.967                3.9\n",
      "304 2024-01-01  28624.069                3.7\n",
      "305 2024-04-01  29016.714                3.9\n",
      "306 2024-07-01  29374.914                4.2\n",
      "307 2024-10-01  29723.864                4.1\n",
      "\n",
      "[308 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Query the data from AWS PostgreSQL\n",
    "with engine.connect() as connection:\n",
    "    df_check = pd.read_sql(\"SELECT * FROM economic_indicators\", connection)\n",
    "\n",
    "print(df_check)  # Display first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf1d134a-cbb0-4f17-976d-1244e754fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                 0\n",
      "GDP                  0\n",
      "Unemployment_Rate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in df_merged\n",
    "missing_values = df_economic.isnull().sum()\n",
    "\n",
    "# Display missing values for each column\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca74df-9305-433b-8a99-40adcf8c32c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
